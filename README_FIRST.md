# FEAGI Mobile App

## üèûÔ∏è Overview

The objective is to build a simple React Native phone app that can display a FEAGI instance in the Brain Visualizer.

It should be able to transmit phone-specific inputs to the FEAGI instance, such as webcam feed and accelerometer.

_Ideally_, two functionally identical apps will be built: one for iPhone, and one for Android. The app should also display correctly on tablets.

## üì± Requirements

- A phone app that runs properly on Android or iPhone (ideally both)

### Technology

- [React Native](https://reactnative.dev/)
- Git/Github
- Your IDE of choice (Visual Studio Code, etc.)

### Screens/Views & UI

- [ ] Home screen (links to other screens)
- [ ] BV (Brain Visualizer) screen
- [ ] Settings screen (should be openable from the BV screen navbar)
- [ ] Navbar
- [ ] Responsive: works on different viewports, and in both portrait & landscape mode

### Functionality

- [ ] Connect to a FEAGI instance running in the playground or NRS (should support both)
- [ ] Get and transmit phone sensor data to FEAGI instance: webcam, gyroscope, accelerometer
- [ ] Allow user to edit basic settings and transmit their changes to FEAGI instance:

### Nice to Have (not required)

- [ ] Functionally identical apps for both iPhone & Android
- [ ] Light/dark mode

## üèÅ Milestones

- [ ] Create the most basic possible app (one screen) and get it running on a phone in test mode
- [ ] Add all screens from the mockup
- [ ] Get the BV running a remote FEAGI instance
- [ ] Successfully communicate phone sensor data to FEAGI
- [ ] Successfully communicate settings changes to FEAGI

## ‚úÖ Deliverables

- [ ] Complete the phone app
- [ ] Create a simple FEAGI genome of any kind
- [ ] Write a technical blog about the experience ([examples](https://neurorobotics.studio/blog))
