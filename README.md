# Feagi Mobile App

## Overview

The objective is to build a simple phone app that can display a FEAGI instance in the Brain Visualizer. 

It should be able to transmit phone-specific inputs to the FEAGI instance, such as webcam feed and accelerometer.

Ideally, the language used will be React Native, and two functionally identical apps will be built: one for iPhone, and one for Android. The app should also display correctly on tablets.

## Requirements

At least one version of the phone app that runs properly on an iPhone or Android.

### Technology
- [React Native](https://reactnative.dev/)
- Git/Github
- Your IDE of choice (Visual Studio Code, etc.)

### Screens/Views & UI
- [ ] Home screen (links to other screens)
- [ ] BV (Brain Visualizer) screen
- [ ] Settings screen (should be openable from the BV screen navbar)
- [ ] Navbar
- [ ] Responsive: works on different viewports, and in both portrait & landscape mode

### Functionality
- [ ] Connect to a FEAGI instance running in the playground or NRS (should support both)
- [ ] Get and transmit phone sensor data to FEAGI instance: webcam, gyroscope, accelerometer
- [ ] Allow user to edit basic settings and transmit their changes to FEAGI instance:

### Nice to Have (not required)
- [ ] Functionally identical apps for both iPhone & Android
- [ ] Light/dark mode

### Milestones
- [ ] Create the most basic possible app (one screen) and get it running on a phone in test mode
- [ ] Add all screens from the mockup 
- [ ] Get the BV running a remote FEAGI instance
- [ ] Successfully communicate phone sensor data to FEAGI
- [ ] Successfully communicate settings changes to FEAGI

### Deliverables
- [ ] Complete the phone app
- [ ] Create a simple FEAGI genome of any kind
- [ ] Write a technical blog about the experience ([examples](https://neurorobotics.studio/blog))
